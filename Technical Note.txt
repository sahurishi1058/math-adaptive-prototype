TECHNICAL NOTE: MATH ADVENTURES ADAPTIVE PROTOTYPE
==================================================

1. SYSTEM ARCHITECTURE & FLOW
--------------------------------------------------
The application follows a modular architecture where the "Adaptive Engine" 
acts as the central decision-maker, separating the user interface from the 
logic and data tracking.

[DATA FLOW DIAGRAM]

      [User] <===> [Main Interface (CLI)]
                            |
                            v
                  [Performance Tracker]
                  (Logs: Time, Accuracy)
                            |
                            v
                   [Adaptive Engine]
             (Input: History -> Output: Next Level)
                            |
                            v
                   [Puzzle Generator]
          (Creates Content based on new Difficulty)

PROCESS DESCRIPTION:
1. Input: User solves a problem generated by the Puzzle Generator.
2. Tracking: The Main Interface captures the answer and calculates time taken.
3. Logging: The Performance Tracker stores the result for session analytics.
4. Decision: The Adaptive Engine evaluates the result against specific thresholds.
5. Adaptation: The system updates the difficulty level for the next iteration.


2. EXPLANATION OF ADAPTIVE LOGIC
--------------------------------------------------
This prototype utilizes a "Rule-Based Adaptive Engine"[cite: 5, 50]. Instead of a 
"black box" machine learning model, we use deterministic if-then logic to 
ensure transparency and immediate feedback.

The logic balances two factors: Mastery (Accuracy) and Fluency (Speed).

THE ALGORITHM:
The logic is encapsulated in the 'game_engine' function:

A. DEMOTION (Struggling)
   - Condition: If the answer is Incorrect.
   - Action: Decrease difficulty (minimum: Level 1).
   - Reasoning: Immediate failure suggests the current cognitive load is 
     too high.

B. PROMOTION (Flow State)
   - Condition: If the answer is Correct AND time_taken < Threshold.
   - Action: Increase difficulty (maximum: Level 3).
   - Reasoning: High accuracy combined with speed indicates "automaticity" 
     (mastery), meaning the user is ready for a harder challenge.

C. MAINTENANCE (Learning Zone)
   - Condition: If the answer is Correct but Slow.
   - Action: Stay at current level.
   - Reasoning: The user understands the concept but needs more practice 
     to build speed and confidence.


3. KEY METRICS TRACKED
--------------------------------------------------
The system tracks the following metrics to influence difficulty changes[cite: 51]:

1. ACCURACY (Boolean):
   The primary driver. A "False" result triggers an immediate level drop to 
   prevent frustration.

2. RESPONSE TIME (Seconds):
   The secondary driver. Determines if a correct answer counts as "Mastery" 
   or just "Understanding."

SPEED THRESHOLDS USED:
- Level 1 (Easy): Must answer in < 5 seconds to promote.
- Level 2 (Medium): Must answer in < 7 seconds to promote.

Note: These thresholds increase as problems get harder (multiplication takes 
longer than simple addition).


4. RATIONALE: WHY RULE-BASED?
--------------------------------------------------
I chose a Rule-Based approach over Machine Learning for this prototype for 
three specific reasons[cite: 52]:

1. NO "COLD START" PROBLEM: 
   A rule-based system works perfectly for the very first user. An ML model 
   (like Reinforcement Learning) would require thousands of training episodes 
   before it learned that "getting an answer wrong" is bad.

2. TRANSPARENCY & DEBUGGING: 
   In an educational context, it is critical to explain *why* a student was 
   moved down a level. "You took 15 seconds" is a clear explanation; "The 
   neural net predicted a 40% probability of failure" is not.

3. SCOPE APPROPRIATENESS: 
   For a prototype with limited difficulty levels (1-3) and session length 
   (10 questions), rules provide a controlled and reliable user experience 
   that demonstrates the concept effectively without the overhead of model 
   training.